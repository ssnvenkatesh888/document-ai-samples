{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66aedf38-a792-46ff-9a1a-110b49ecc501",
   "metadata": {},
   "source": [
    "# Swap OCR Confusion Characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d5b4c9-2440-43e5-ba73-0fae68988920",
   "metadata": {},
   "source": [
    "* Author: docai-incubator@google.com"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4533ec78-11f1-4aca-9332-43517bf37545",
   "metadata": {},
   "source": [
    "## Disclaimer\n",
    "\n",
    "This tool is not supported by the Google engineering team or product team. It is provided and supported on a best-effort basis by the **DocAI Incubator Team**. No guarantees of performance are implied."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a3ccb65-96bc-493d-b92c-41b11cac3daa",
   "metadata": {},
   "source": [
    "# Objective\n",
    "This is a post processing tool to modify ocr-text, all characters/symbols are filtered based on provided confidence threshold(i.e, confidence_threshold) and then all these characters/symbols are replaced based on provided mapping dictionary(i.e, swapper) in ocr-text\n",
    " to normalize year in date related entities from 19xx to 20xx. Document AI processors will give a normalized_value attribute for date entities in Document Object and sometimes this normalized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d94cd4-355c-40a9-a5a4-2e8551e70f35",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "* Vertex AI Notebook\n",
    "* GCS Folder Path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb954e7-a064-48aa-aaaa-de37818e4757",
   "metadata": {},
   "source": [
    "# Step-by-Step Procedure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ba1003-58d0-46bb-8232-63b796ec4bf2",
   "metadata": {},
   "source": [
    "## Import the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c53066c4-af1c-4cf5-8dd2-fcb21c2810f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2024-06-18 11:02:25--  https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 29735 (29K) [text/plain]\n",
      "Saving to: ‘utilities.py’\n",
      "\n",
      "utilities.py        100%[===================>]  29.04K  --.-KB/s    in 0.002s  \n",
      "\n",
      "2024-06-18 11:02:25 (15.7 MB/s) - ‘utilities.py’ saved [29735/29735]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run this cell to download utilities module\n",
    "!wget https://raw.githubusercontent.com/GoogleCloudPlatform/document-ai-samples/main/incubator-tools/best-practices/utilities/utilities.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1bf0dd2f-2db4-4225-9a9e-9820b6e2bd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import documentai_v1beta3 as documentai\n",
    "from google.cloud import storage\n",
    "from typing import Tuple, List, Dict\n",
    "from utilities import (file_names,documentai_json_proto_downloader,store_document_as_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc3187de-60e3-405b-982d-65bf1f28ff74",
   "metadata": {},
   "source": [
    "## 2. Input Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "226740e0-22ca-444b-8ae1-bc25581877e0",
   "metadata": {},
   "source": [
    "* **GCS_INPUT_PATH** : GCS folder path containing DocAI OCR Processor results in JSON format with Symbols data in it. \n",
    "* **GCS_OUTPUT_PATH** : GCS folder path to store post-processed results\n",
    "* **CONFIDENCE_THRESHOLD** : Based on this value, all swapping process takes place. It range is (0, 1).\n",
    "* **SWAPPER** : It is a dictionary, containing mapper configurations, {‘old_char’: ‘new_char’,...}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ddc3b6d-7d8f-4998-b567-a923b97a86a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_INPUT_FOLDER =  \"gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/\"\n",
    "GCS_OUTPUT_FOLDER = \"gs://test_data_program_team/tools-samples-transfer/swap_ocr/output\"\n",
    "CONFIDENCE_THRESHOLD = 0.65\n",
    "SWAPPER = {\n",
    "    \")\": \"J\",\n",
    "    \"0\": \"Q\",\n",
    "    \"5\": \"S\",\n",
    "    \"1\": \"I\",\n",
    "    \"2\": \"Z\",\n",
    "    \"8\": \"B\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2533a49a-ba10-47fa-a3f8-fe788eadc6e3",
   "metadata": {},
   "source": [
    "## 3. Run Below Code-Cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16732718-d5f0-4cee-a4a6-634fe6926f5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swapping process started based on provided confidence threshold and swapper_dict\n",
      "Processing File: 1.json ...\n",
      "\t Post-processed file storing at gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/1.json\n",
      "Processing File: 2.json ...\n",
      "\t Post-processed file storing at gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/2.json\n",
      "Processing File: 3.json ...\n",
      "\t Post-processed file storing at gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/3.json\n",
      "Processing File: 4.json ...\n",
      "\t Post-processed file storing at gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/4.json\n",
      "Processing File: 5.json ...\n",
      "\t Post-processed file storing at gs://test_data_program_team/tools-samples-transfer/swap_ocr/input/5.json\n",
      "Process Completed!!!\n"
     ]
    }
   ],
   "source": [
    "def swap_confusion_chars(doc, confidence_threshold=0.75):\n",
    "    \"\"\"\n",
    "    Swap characters in the document text with characters from the swapper mapping\n",
    "    based on a confidence threshold.\n",
    "\n",
    "    Parameters:\n",
    "    doc (object): The document object containing text and page symbols.\n",
    "    swapper (dict): A dictionary mapping characters to their replacement characters.\n",
    "    confidence_threshold (float): The confidence threshold below which characters will be swapped.\n",
    "\n",
    "    Returns:\n",
    "    object: The modified document object with swapped characters.\n",
    "    \"\"\"\n",
    "    text = doc.text\n",
    "    for page in doc.pages:\n",
    "        for _, symbol in enumerate(page.symbols):\n",
    "            conf = symbol.layout.confidence\n",
    "            if conf <= confidence_threshold:\n",
    "                text_segment = symbol.layout.text_anchor.text_segments[0]\n",
    "                start_ind,end_i = text_segment.start_index, text_segment.end_index\n",
    "                char = text[start_ind:end_i]\n",
    "                if char in SWAPPER:\n",
    "                    # Modifying docai text inplace\n",
    "                    text = text[:start_ind]+SWAPPER[char]+text[end_i:]\n",
    "                    doc.text = text\n",
    "    return doc\n",
    "\n",
    "\n",
    "splits = GCS_INPUT_FOLDER.strip(\"/\").split(\"/\")\n",
    "input_bucket, input_folder = splits[2], \"/\".join(splits[3:])\n",
    "output_bucket, output_folder = splits[2], \"/\".join(splits[3:])\n",
    "_, files_dict = file_names(GCS_INPUT_FOLDER)\n",
    "#input_bucket, input_folder, output_bucket, output_folder, files_dict\n",
    "\n",
    "print(\"Swapping process started based on provided confidence threshold and swapper_dict\")\n",
    "for fn, fp in files_dict.items():\n",
    "    print(f\"Processing File: {fn} ...\")\n",
    "    doc_1 = documentai_json_proto_downloader(input_bucket, fp)\n",
    "    doc_2 = swap_confusion_chars(doc_1, CONFIDENCE_THRESHOLD)\n",
    "    json_str = documentai.Document.to_json(doc_2, including_default_value_fields=False)\n",
    "    out_fp = f\"{output_folder}/{fn}\"\n",
    "    print(f\"\\t Post-processed file storing at gs://{output_bucket}/{out_fp}\")\n",
    "    store_document_as_json(json_str, output_bucket, out_fp)\n",
    "print(\"Process Completed!!!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab282e87-cb9e-425f-8540-686bfb636902",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1688da22-1fbf-464b-98f2-e82767ffa613",
   "metadata": {},
   "source": [
    "<table>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <b>Pre-processed data</b>\n",
    "        </td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>\n",
    "            <img src='./Images/input_image.png' width=600 height=600></img>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea3c6f4-987b-4391-a837-496de18f493a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m107",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m107"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
